{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656f40a8",
   "metadata": {},
   "source": [
    "# SmartSign RAG: Data Ingestion & Preprocessing\n",
    "\n",
    "This notebook handles the acquisition of the GTSRB dataset, extracts sample images for each traffic sign class, and prepares the catalog for multimodal indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b6753",
   "metadata": {},
   "source": [
    "Ingestion & Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc22caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# 1. Kaggle API Configuration\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = \".\" \n",
    "\n",
    "try:\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "except ImportError:\n",
    "    print(\"Error: Please install kaggle library via 'pip install kaggle'\")\n",
    "    exit()\n",
    "\n",
    "def setup_data():\n",
    "    # Authenticate with Kaggle\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    dataset = \"meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\"\n",
    "    zip_file = \"gtsrb-german-traffic-sign.zip\"\n",
    "\n",
    "    # 2. Download and Unzip Dataset\n",
    "    if not os.path.exists(zip_file):\n",
    "        print(f\"Downloading dataset: {dataset}...\")\n",
    "        try:\n",
    "            api.dataset_download_files(dataset, path='.', unzip=True)\n",
    "            print(\"Download and extraction complete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading dataset: {e}\")\n",
    "            return\n",
    "\n",
    "    # 3. Create Output Directory\n",
    "    output_dir = \"data/samples\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 4. Locate the 'Train' folder (handling nested structures)\n",
    "    # This searches for the folder containing the '0' or '00000' subfolder\n",
    "    search_paths = glob(\"**/Train\", recursive=True) + glob(\"**/train\", recursive=True)\n",
    "    if not search_paths:\n",
    "        print(\"Error: Could not find 'Train' directory. Check your dataset structure.\")\n",
    "        return\n",
    "    \n",
    "    train_path = search_paths[0]\n",
    "    print(f\"Source data found at: {train_path}\")\n",
    "\n",
    "    # 5. Extract One Sample per Class\n",
    "    sample_mapping = []\n",
    "    # Identify subdirectories that are digits (classes 0-42)\n",
    "    classes = sorted([d for d in os.listdir(train_path) if d.isdigit()])\n",
    "\n",
    "    print(f\"Copying samples for {len(classes)} classes...\")\n",
    "\n",
    "    for cls in classes:\n",
    "        cls_dir = os.path.join(train_path, cls)\n",
    "        # Find images with supported extensions\n",
    "        images = [f for f in os.listdir(cls_dir) if f.lower().endswith(('.png', '.jpg', '.ppm'))]\n",
    "        \n",
    "        if images:\n",
    "            images.sort() # Take the first image alphabetically\n",
    "            src_path = os.path.join(cls_dir, images[0])\n",
    "            \n",
    "            # Save as class_X.png (converting '00014' to '14')\n",
    "            clean_id = str(int(cls))\n",
    "            dest_filename = f\"class_{clean_id}.png\"\n",
    "            dest_path = os.path.join(output_dir, dest_filename)\n",
    "            \n",
    "            shutil.copy(src_path, dest_path)\n",
    "            sample_mapping.append({\"class_id\": clean_id, \"image_path\": dest_path})\n",
    "\n",
    "    # 6. Save Catalog for LangChain\n",
    "    df = pd.DataFrame(sample_mapping)\n",
    "    df.to_csv(\"data/image_catalog.csv\", index=False)\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Success! {len(sample_mapping)} images saved to '{output_dir}'\")\n",
    "    print(\"Catalog created: 'data/image_catalog.csv'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    setup_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5275f129",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba9eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the created catalog\n",
    "catalog_path = \"data/image_catalog.csv\"\n",
    "\n",
    "if os.path.exists(catalog_path):\n",
    "    df_preview = pd.read_csv(catalog_path)\n",
    "    \n",
    "    # Display the first 10 signs for verification\n",
    "    num_samples = 10\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if i < len(df_preview):\n",
    "            img_path = df_preview.iloc[i]['image_path']\n",
    "            class_id = df_preview.iloc[i]['class_id']\n",
    "            \n",
    "            img = mpimg.imread(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f\"Class ID: {class_id}\")\n",
    "            axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Sample mapping from CSV:\")\n",
    "    print(df_preview.head(10))\n",
    "else:\n",
    "    print(\"Error: image_catalog.csv not found. Run the ingestion cell first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
