{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e263a9",
   "metadata": {},
   "source": [
    "1️⃣ Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a35b3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from evaluation.pipeline import run_evaluation\n",
    "from evaluation.metrics import (\n",
    "    compute_retrieval_metrics,\n",
    "    compute_answer_metrics,\n",
    "    compute_rag_quality_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7038c",
   "metadata": {},
   "source": [
    "2️⃣ Load Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f8852d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 evaluation examples\n"
     ]
    }
   ],
   "source": [
    "EVAL_DATASET_PATH = Path(\"evaluation/eval_dataset.json\")\n",
    "\n",
    "with open(EVAL_DATASET_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset_json = json.load(f)\n",
    "\n",
    "eval_dataset = dataset_json.get(\"samples\", [])\n",
    "print(f\"Loaded {len(eval_dataset)} evaluation examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d7d2f",
   "metadata": {},
   "source": [
    "3️⃣ Запускаємо evaluation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2447428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 evaluation examples\n",
      "[1/8] Question processed\n",
      "[2/8] Question processed\n",
      "[3/8] Question processed\n",
      "[4/8] Question processed\n",
      "[5/8] Question processed\n",
      "[6/8] Question processed\n",
      "[7/8] Question processed\n",
      "[8/8] Question processed\n",
      "Evaluation finished. 8 samples processed.\n",
      "Results saved to evaluation\\reports\\eval_results.json\n"
     ]
    }
   ],
   "source": [
    "results = run_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a6eb3",
   "metadata": {},
   "source": [
    "4️⃣ Перетворюємо результати в DataFrame для зручного перегляду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd57efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee074b",
   "metadata": {},
   "source": [
    "5️⃣ Виводимо перші кілька рядків"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbeeb8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>expected_answer</th>\n",
       "      <th>rag_answer</th>\n",
       "      <th>retrieved_docs</th>\n",
       "      <th>retrieval_score</th>\n",
       "      <th>answer_score</th>\n",
       "      <th>rag_quality_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>What does the slippery road traffic sign mean ...</td>\n",
       "      <td>The Slippery When Wet traffic sign warns drive...</td>\n",
       "      <td>Based on the provided context, the Slippery Wh...</td>\n",
       "      <td>[{'page_content': 'Traffic sign: Solid Broken ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>What is the meaning of the oil slick traffic s...</td>\n",
       "      <td>The oil slick traffic sign indicates the prese...</td>\n",
       "      <td>Based on the provided context, the oil slick t...</td>\n",
       "      <td>[{'page_content': 'Traffic sign: Oil Slick. Ca...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>What does a triangular warning sign generally ...</td>\n",
       "      <td>A triangular warning sign indicates a hazard o...</td>\n",
       "      <td>Based on the provided context, a triangular wa...</td>\n",
       "      <td>[{'page_content': 'These are other vehicle cla...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>Where is parking on the pavement allowed?</td>\n",
       "      <td>Parking on the pavement is allowed in specific...</td>\n",
       "      <td>Based on the provided context, parking on the ...</td>\n",
       "      <td>[{'page_content': 'over manhole covers and oth...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>What category do slippery road signs belong to?</td>\n",
       "      <td>Slippery road signs belong to warning signs.</td>\n",
       "      <td>Based on the provided context, the category fo...</td>\n",
       "      <td>[{'page_content': 'Traffic sign: Oil Slick. Ca...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q6</td>\n",
       "      <td>How should a driver react when seeing a slippe...</td>\n",
       "      <td>A driver should exercise caution, reduce speed...</td>\n",
       "      <td>Based on the provided context, the relevant in...</td>\n",
       "      <td>[{'page_content': 'Traffic sign: Slippery When...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q7</td>\n",
       "      <td>Is the slippery road sign a regulatory or warn...</td>\n",
       "      <td>It is a warning sign, used to alert drivers to...</td>\n",
       "      <td>Unfortunately, the context provided does not i...</td>\n",
       "      <td>[{'page_content': 'Traffic sign: Riders Prohib...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q8</td>\n",
       "      <td>What legal role do traffic signs have under Ge...</td>\n",
       "      <td>Traffic signs are legally binding instructions...</td>\n",
       "      <td>According to the provided context, traffic sig...</td>\n",
       "      <td>[{'page_content': 'Traffic sign: no passing ve...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question  \\\n",
       "0  Q1  What does the slippery road traffic sign mean ...   \n",
       "1  Q2  What is the meaning of the oil slick traffic s...   \n",
       "2  Q3  What does a triangular warning sign generally ...   \n",
       "3  Q4          Where is parking on the pavement allowed?   \n",
       "4  Q5    What category do slippery road signs belong to?   \n",
       "5  Q6  How should a driver react when seeing a slippe...   \n",
       "6  Q7  Is the slippery road sign a regulatory or warn...   \n",
       "7  Q8  What legal role do traffic signs have under Ge...   \n",
       "\n",
       "                                     expected_answer  \\\n",
       "0  The Slippery When Wet traffic sign warns drive...   \n",
       "1  The oil slick traffic sign indicates the prese...   \n",
       "2  A triangular warning sign indicates a hazard o...   \n",
       "3  Parking on the pavement is allowed in specific...   \n",
       "4       Slippery road signs belong to warning signs.   \n",
       "5  A driver should exercise caution, reduce speed...   \n",
       "6  It is a warning sign, used to alert drivers to...   \n",
       "7  Traffic signs are legally binding instructions...   \n",
       "\n",
       "                                          rag_answer  \\\n",
       "0  Based on the provided context, the Slippery Wh...   \n",
       "1  Based on the provided context, the oil slick t...   \n",
       "2  Based on the provided context, a triangular wa...   \n",
       "3  Based on the provided context, parking on the ...   \n",
       "4  Based on the provided context, the category fo...   \n",
       "5  Based on the provided context, the relevant in...   \n",
       "6  Unfortunately, the context provided does not i...   \n",
       "7  According to the provided context, traffic sig...   \n",
       "\n",
       "                                      retrieved_docs  retrieval_score  \\\n",
       "0  [{'page_content': 'Traffic sign: Solid Broken ...              1.0   \n",
       "1  [{'page_content': 'Traffic sign: Oil Slick. Ca...              1.0   \n",
       "2  [{'page_content': 'These are other vehicle cla...              0.0   \n",
       "3  [{'page_content': 'over manhole covers and oth...              0.5   \n",
       "4  [{'page_content': 'Traffic sign: Oil Slick. Ca...              1.0   \n",
       "5  [{'page_content': 'Traffic sign: Slippery When...              1.0   \n",
       "6  [{'page_content': 'Traffic sign: Riders Prohib...              1.0   \n",
       "7  [{'page_content': 'Traffic sign: no passing ve...              1.0   \n",
       "\n",
       "   answer_score  rag_quality_score  \n",
       "0      0.703704              0.852  \n",
       "1      0.791667              0.896  \n",
       "2      0.809524              0.405  \n",
       "3      0.666667              0.583  \n",
       "4      0.166667              0.583  \n",
       "5      0.863636              0.932  \n",
       "6      0.928571              0.964  \n",
       "7      0.714286              0.857  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df29655",
   "metadata": {},
   "source": [
    "6️⃣ Додаткові підрахунки: середні метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6763042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Retrieval Score: 0.812\n",
      "Average Answer Score: 0.706\n",
      "Average RAG Quality Score: 0.759\n"
     ]
    }
   ],
   "source": [
    "avg_retrieval = df['retrieval_score'].mean()\n",
    "avg_answer = df['answer_score'].mean()\n",
    "avg_rag_quality = df['rag_quality_score'].mean()\n",
    "\n",
    "print(f\"Average Retrieval Score: {avg_retrieval:.3f}\")\n",
    "print(f\"Average Answer Score: {avg_answer:.3f}\")\n",
    "print(f\"Average RAG Quality Score: {avg_rag_quality:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd85acd",
   "metadata": {},
   "source": [
    "7️⃣ Збереження DataFrame у CSV для подальшого аналізу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae958f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to evaluation\\reports\\eval_results.csv\n"
     ]
    }
   ],
   "source": [
    "REPORTS_DIR = Path(\"evaluation/reports\")\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(REPORTS_DIR / \"eval_results.csv\", index=False)\n",
    "print(f\"Results saved to {REPORTS_DIR / 'eval_results.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoftServeInternship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
