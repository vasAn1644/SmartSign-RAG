
# **PRD: SmartSign RAG â€“ Multimodal Traffic Rules Assistant**

### **1. Problem & Users**

**1.1 Problem Statement**
Road traffic regulations (StVO) are often dense, legalistic, and difficult to navigate. There is a significant "knowledge gap" between seeing a physical sign on the road and understanding its precise legal implications. Standard search tools often separate visual data from regulatory text, leading to a lack of context.

**1.2 Target Audience**

* **Expatriates & International Drivers:** Individuals moving to Germany who need to translate visual signs into understandable rules in English.
* **Driving Students:** Learners preparing for theory exams who require visual-to-rule reinforcement.
* **Legal/Safety Educators:** Professionals needing grounded, source-backed explanations of traffic laws.

---

### **2. MVP Scope**

**2.1 In-Scope (Features)**

* **Multimodal Semantic Retrieval:** Finding relevant road rules via natural language queries (e.g., "signs for slippery roads") and visual descriptions (e.g., "black toad on a white triangle").
* **Metadata-Driven Image Priority:** A custom reranking logic that prioritizes chunks containing `image_url` to ensure visual answers are always provided.
* **Grounded Generation:** Responses generated by Llama 3.3-70B, strictly constrained by the retrieved StVO context.
* **Interactive UI:** A Streamlit interface that renders Markdown images and provides expandable sources for verification.

**2.2 Out-of-Scope**

* **Real-time Video Processing:** The system indexes static datasets, not live video streams.
* **Personal Driving Logs:** No user profile or history tracking in the MVP.
* **Legal Liability:** The tool is educational and not a substitute for official legal advice.

---

### **3. Content & Data**

**3.1 Data Sources**

* **StVO (PDF):** The primary legal source for official traffic regulations.
* **Wikipedia (Scraped):** A rich multimodal dataset of German road signs with high-quality images and category labels.
* **IamExpat & Driving Portals:** Web-crawled text providing practical, easy-to-understand driving context.

**3.2 Data Linkage**
Data is unified into a single vector space using **ChromaDB**. Text chunks are enriched with metadata tags: `image_url`, `source`, `category`, and `type` (image, text, or pdf).

---

### **4. Example Queries**

| Query Type | Example |
| --- | --- |
| **Visual Search** | "Explain the sign with a black toad and show it." |
| **Complex Context** | "What rules apply in road tunnels and what signs are used?" |
| **Analytical** | "What is the difference between mandatory and prohibitory signs?" |
| **Specific Rule** | "What is the penalty for ignoring a 'No Entry' sign?" |

---

### **5. Success Metrics**

* **Retrieval Accuracy (R@8):** Success rate of finding the correct sign/rule in top-8 results (Current: **81.2%**).
* **Answer Faithfulness:** Degree to which the AI stays within the provided context (Current: **70.6%**).
* **Inference Latency:** Total response time < 3s (Enabled by **Groq LPU** acceleration).
* **Visual Success Rate:** 100% of responses to sign-related queries must include a rendered image.

---

### **6. Technical Stack**

* **Orchestration:** **LangChain** (RunnableParallel/LCEL) for complex pipeline management.
* **Inference Engine:** **Groq Cloud** (Llama 3.3-70B) for high-speed, high-reasoning output.
* **Embeddings:** **Hugging Face** (Sentence-Transformers) for semantic text-to-vector mapping.
* **Vector Database:** **ChromaDB** with persistent storage.
* **Frontend:** **Streamlit** (Multimodal Markdown rendering).

---

### **7. Key Optimization (Technical Moat)**

The system implements a **Metadata-Aware Reranking** strategy. Since standard embeddings may favor dense text over short image descriptions, the pipeline manually re-orders the retrieved documents to ensure that visual metadata is surfaced to the LLM as a priority, ensuring a truly multimodal user experience.


